---
title: "Working with data frames"
author: "Mark Andrews"
date: "October 9, 2017"
output:
  pdf_document:
    keep_tex: yes
editor_options:
  chunk_output_type: inline
---
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, include=TRUE, message = FALSE, warning = FALSE)
```


```{r}
library(dplyr)
library(readr)
options(tibble.width = Inf) 
```


# Introduction

Most of time when we are working with data, we work with *data frames*. Data frames can be seen as similar to spreadsheets, i.e. with multiple rows and multiple columns, and each column representing a variable. In this note, we will deal with data-frame using the `tidyverse` approach. You can do more or less everything shown below in a `base R` way too, but on balance I think the `tidyverse` way is the more efficient way and I think it is more likely to be way we all be doing it in the future anyway. 

# Read in a data frame from csv file

We'll start by reading in a csv file as a data frame (which could be done from the RStudio `Import Dataset` menu in `Environment`):

```{r}
(Df <- read_csv('../data/LexicalDecision.csv'))
```
Note that `read_csv`, which is part of the `readr` package, which is loaded above.

# Quick summary of your data frame

```{r}
summary(Df)
```

# Rename variable names 

You can rename as many variables as you like as follows:
```{r}
(Df <- rename(Df,
              word = item,
              reaction.time = latency))
```
The `rename` function takes a data-frame and returns a new data frame. In other words, it does not affect the original data-frame, but produces a copy[^copy] of the original but the variables renamed. 

[^copy]: It's not actually a copy of the data but a copy of the pointers to the data. That means that these operations are both fast and memory efficient.

# Subsetting your data frame

In any data analysis, a lot of time is spent selecting subsets of rows and columns of our data-frame. Doing so efficiently makes everything quicker and easier. 

## Choose a subset of variables (i.e., columns)

Using the `select` function, you will just list out the names of the variables you want to keep:
```{r}
select(Df, subject, word, accuracy, reaction.time)
```

Sometimes, especially when you have many variables, selecting all those you want to keep by explicitly writing down their names as above can be a lot of work. Here are some short-cuts. Let's say you want to keep all but the variables `valence`, you could do:
```{r}
select(Df, -valence)
```
If you wanted to keep all but `valence` and `frequency`, you can do 
```{r}
select(Df, -valence, -frequency)
```
Note that the above code effectively *deletes* the `valence` and `frequency` variables. 

We can also select sequences of variables. For example, we could keep all variables starting with the variables `subject` and ending with `length` as follows:
```{r}
select(Df, subject:length)
```

Although we won't cover them here, there are other more powerful tricks that use *regular expressions*. These are very handy for selecting variables that all begin with the same prefix, e.g. `foo-1`, `foo-2`, `foo-3` ... `foo-78`. 

One final handy trick is the `everything` function. Let's say you want to move the variable `frequency` to be the first variable in the data-frame. You could do
```{r}
select(Df, frequency, everything())
```


## Choose a subset of the observations (i.e., rows)

If you want to select some rows, you can use a `slice`. In the following, we choose rows 10 to 20:
```{r}
slice(Df, 10:20)
```
and here we choose rows 10, 20, 30, 40-45.
```{r}
slice(Df, c(10, 20, 30, 40:45)) # 
```
and so on. 

## Filtering observations

Often, slicing is not the easiest ways to select our rows. In fact, it is best to use `slice` only when you know exactly the row indices of the rows you want to keep. For general situtations, it is best to use `filter`. For example, the following will allow us to select only those observations where the reaction times are less than 2000 milliseconds.
```{r}
filter(Df, reaction.time < 2000)
```
While this will allow us to select the observations where the reaction times are above 200 and below 2000 milliseconds.
```{r}
filter(Df, reaction.time > 200 & reaction.time < 2000)
```

We can also filter more than one variable simultaneously. For example, here we'll filter our those observations where the response was accurate (this is denoted by a value of `1`), the reaction time was between 250 and 750, and the length of the word was between 2 and 5. 
```{r}
filter(Df,
       accuracy == 1,
       reaction.time > 250 & reaction.time < 750,
       length %in% seq(2, 5))

```

# Sorting rows 

The `arrange` function will sort rows. You just specify which columns to sort by. For example, to sort by `reaction.time`, you'd do:
```{r}
arrange(Df, reaction.time)
```
To sort by `length` first and then by `reaction.time`, do 
```{r}
arrange(Df, length, reaction.time)
```
You can sort in descending order by using the `desc` function around the variable name. For example, here we sort by reaction time for largest to smallest: 
```{r}
arrange(Df, desc(reaction.time))
```


# Adding new variables

The `mutate` function adds new variables. For example, let's say we want to add a new variable that is the logarithm of the frequency of the word. We would do this by 
```{r}
mutate(Df, log.frequency = log(frequency))
```

The previous code appended the new `log.frequency` variable onto the end of the data-frame. If we use the same new for the new variable, we'll replace the old varibale, e.g. 
```{r}
mutate(Df, frequency = log(frequency))
```

If you want to create new variables and only keep the new variables, dropping the old ones, you can use `transmute`. For example, here we create three new variables, keep these and throw away the original variables:

```{r}
transmute(Df,
          fast.rt = if_else(reaction.time < 500, 'fast', 'not.fast'),
          short.word = if_else(length <= 3, 'short', 'not.short'),
          frequency = log(frequency))
```

# Summarizing your variables

You can summarize your variables using `summarize` (or `summarise` if you prefer British-English spellings):
```{r}
summarise(Df, 
          mean = mean(reaction.time), 
          median = median(reaction.time), 
          stdev = sd(reaction.time), 
          n = n() # This gives counts
)
```

Often we want to produce summaries of our variables for different groups of observations. In this case, an obvious example is to group our observations according to whether the response for correct or not, and then produce summaries for each subset of data. The way to do this is with the `group_by` function combined with the `summarize` function. In particular, first you group, then you summarize. For example,

```{r}
Df.tmp <- group_by(Df, accuracy) # Create a tmp Df, where the data are grouped
summarize(Df.tmp,
          mean = mean(reaction.time), 
          median = median(reaction.time), 
          stdev = sd(reaction.time), 
          n = n()
)
```
The above code can be done on one line, and without the need for the temporary data-frame, by using a so-called *pipe*. The pipe is given by the command `%>%`. It takes the output from one function and passes it to another function. The above code using the pipe is
```{r}
group_by(Df, accuracy) %>%
  summarize(mean = mean(reaction.time),
            median = median(reaction.time),
            stdev = sd(reaction.time),
            n = n()
  )
```

# Combining operations with %>% 

Often, when data wrangling, we want to combine repeatedly apply functions to our data-frame. The pipe can be very helpful when doing this. As an example, let's say we want to filter out the very fast and the very slow reaction times and the incorrect responses, and then group by subject identity, and calculate the mean reaction time per subject, and then sort by this. To do this, we would do
```{r}
Df %>% 
  filter(reaction.time > 250 & reaction.time < 1250,
         accuracy == 1) %>%
  group_by(subject) %>%
  summarise(mean.rt = mean(reaction.time)) %>%
  arrange(mean.rt)
```

