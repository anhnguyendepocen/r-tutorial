---
title: "Introducing data frames"
author: "Mark Andrews"
date: "April 5, 2017"
output:
  pdf_document: default
  html_notebook: default
editor_options:
  chunk_output_type: inline
---

# Introduction

Most of time, when we are working with data, we work with *data frames*. Data frames can be seen as similar to spreadsheets, i.e. with multiple rows and multiple columns, and each column representing a variable. 

We'll start by reading in a csv file as a data frame:

```{r}
Df <- read.csv('../data/LexicalDecision.csv', header=T)
```

# Examining the data frame

If you want to see the data frame in a spreadsheet style do *View(Df)*. The following *head* and *tail* commands allow you to see the top and bottom, respectively, of the data frame, and often that's all you need to know how it is laid out. 

```{r}
head(Df) # Gives first 6 rows by default
head(Df, 10) # You can ask for as many rows as you like
tail(Df) # Last 6 rows
tail(Df, 8) # Last 8 rows
```

We can also use the generic functions *str* and *summary* to get a better understanding of the information in the data frame:
```{r}
str(Df)
summary(Df)
```

We can use *dim* to see the size of the data frame:
```{r}
dim(Df)
```


# Subsetting the data frame

We can slice the data frame by rows, and by columns, and by both simultaneously, to create new data frames that are subsets of the original. Here are some examples:

```{r}
Df[1:10,] # Rows 1 to 10, all cols
Df[10:20, c(1, 2)] # Rows 10 to 20, cols 1 and 2
Df[1:10, c('subject', 'valence')] # Rows 1 to 10, cols 'subject' and 'valence'
```

We can also use the *subset* command to subset the data frame in more interestings ways:
```{r}
Df.new <- subset(Df, latency > 2000) # Only rows where latency takes value greater than 2000
# Return rows where responses are accurate and latency is less than 2000
Df.new <- subset(Df, accuracy == 1 & latency < 2000) 
```


# Getting and changing variable (column) names

This will return the names of the columns
```{r}
(original.col.names <- names(Df) )
```
and so you could do the following:
```{r}
names(Df)[2] <- 'words' # Rename name of second column
names(Df)[c(2, 3)] <- c('words', 'correct') # Rename names of second and third column
names(Df) <- original.col.names
```

# Adding/deleting variables 

We can create a new variable (column) simply as follows. This creates a new variable called *loglatency*, which is the logarithm of the latency variable.
```{r}
Df$loglatency <- log(Df$latency)
```

We can delete this, or any other, with
```{r}
Df$loglatency <- NULL
```

As some further example, we could create a new binary variable that indicates if the latency variable is fast, where fast is defined as anything less than 500.

```{r}
Df$fast.rt <- Df$latency < 500
```
and we could then do
```{r}
sum(Df$fast.rt)
```
to see that `r sum(Df$fast.rt)` of the `r length(Df$latency)` reaction times are fast, according to this definition. 

To create more interesting categorical variables from continuous ones, we can use the *cut* command. For example, this will cut the *valence* variable into three categories and create a new variable named *valence.category*:
```{r}
# values in [0, 3) are labelled "negative"
# values in [3, 6) are labelled "neutral"
# values in [6, 10) are labelled "positive"
Df$valence.category <- cut(Df$valence, 
                             breaks = c(0, 3, 6, 10), 
                             labels = c('negative', 'neutral', 'positive'))
```

# Aggregations over variables

Often, we want to group observations according to certain categories and apply functions to these grouped data. For example, in this data frame, we might like to group the observations according to the valence category just created and then calculate the mean values of these groups: 
```{r}
aggregate(latency ~ valence.category, data=Df, mean)
```
As another example, we could get the mean accuracy and latency by valence category
```{r}
aggregate(cbind(accuracy, latency) ~ valence.category, data=Df, mean)
```


# Combining and merging data frames

For these examples, we'll first read in some new data sets:
```{r}
lexicon.A <- read.csv('../data/lexiconA.csv', header=T)
lexicon.B <- read.csv('../data/lexiconB.csv', header=T)
lexicon.C <- read.csv('../data/lexiconC.csv', header=T)
behav.data <- read.csv('../data/data.csv', header=T)
```

The data frames *lexicon.A* and *lexicon.C* have the same column names and so we can stack them on top of each other:
```{r}
rbind(lexicon.A, lexicon.C) 
```

The data frames *lexicon.A* and *behav.data* have the same number of rows, so we can stack them side by side:
```{r}
cbind(lexicon.A, behav.data)
```

A more interesting case is where we want to merge values from two data frames according to common variables:
```{r}
merge(lexicon.A, lexicon.B)
```

